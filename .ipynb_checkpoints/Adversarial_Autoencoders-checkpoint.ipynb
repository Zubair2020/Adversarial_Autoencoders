{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "sct4Yam2F4mc"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, GaussianNoise\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses\n",
    "from keras.utils import to_categorical\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.animation as animation\n",
    "import imageio\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NsDpsnR7GfwI"
   },
   "outputs": [],
   "source": [
    "class AdversarialAutoencoder():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 10\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the encoder / decoder\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        # The generator takes the image, encodes it and reconstructs it\n",
    "        # from the encoding\n",
    "        encoded_repr = self.encoder(img)\n",
    "        reconstructed_img = self.decoder(encoded_repr)\n",
    "\n",
    "        # For the adversarial_autoencoder model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator determines validity of the encoding\n",
    "        validity = self.discriminator(encoded_repr)\n",
    "\n",
    "        # The adversarial_autoencoder model  (stacked generator and discriminator)\n",
    "        self.adversarial_autoencoder = Model(img, [reconstructed_img, validity])\n",
    "        self.adversarial_autoencoder.compile(loss=['mse', 'binary_crossentropy'],\n",
    "            loss_weights=[0.999, 0.001],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_encoder(self):\n",
    "    # Encoder\n",
    "\n",
    "      img = Input(shape=self.img_shape)\n",
    "\n",
    "      h = Flatten()(img)\n",
    "      h = Dense(512)(h)\n",
    "      h = LeakyReLU(alpha=0.2)(h)\n",
    "      h = Dense(512)(h)\n",
    "      h = LeakyReLU(alpha=0.2)(h)\n",
    "      mu = Dense(self.latent_dim)(h)\n",
    "      log_var = Dense(self.latent_dim)(h)\n",
    "\n",
    "      def sampling(args):\n",
    "          mu, log_var = args\n",
    "          epsilon = K.random_normal(shape=K.shape(mu), mean=0., stddev=1.)\n",
    "          return mu + K.exp(log_var / 2) * epsilon\n",
    "\n",
    "      latent_repr = Lambda(sampling, output_shape=(self.latent_dim,))([mu, log_var])\n",
    "\n",
    "      return Model(img, latent_repr)\n",
    "\n",
    "\n",
    "    def build_decoder(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = model(z)\n",
    "\n",
    "        return Model(z, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "        model.summary()\n",
    "\n",
    "        encoded_repr = Input(shape=(self.latent_dim, ))\n",
    "        validity = model(encoded_repr)\n",
    "\n",
    "        return Model(encoded_repr, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "        # Load the dataset\n",
    "        (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Select a random batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            # Generate a batch of fake latent vectors\n",
    "            latent_fake = self.encoder.predict(imgs)\n",
    "\n",
    "            # Generate a batch of real latent vectors\n",
    "            latent_real = np.random.normal(size=(batch_size, self.latent_dim))\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the discriminator on real and fake latent vectors\n",
    "            d_loss_real = self.discriminator.train_on_batch(latent_real, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(latent_fake, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            # Train the generator on a batch of images\n",
    "            g_loss = self.adversarial_autoencoder.train_on_batch(imgs, [imgs, valid])\n",
    "\n",
    "            # Print the loss and accuracy for each epoch\n",
    "            print(f\"{epoch} [D loss: {d_loss[0]:.2f}, acc: {100 * d_loss[1]:.2f}%]\"\n",
    "                  f\" [G loss: {g_loss[0]:.2f}, mse: {g_loss[1]:.2f}]\")\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.decoder.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 25 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c, figsize=(10, 10))\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "\n",
    "        plt.suptitle(f\"MNIST dataset Generated Images (Epoch {epoch})\", fontsize=24)\n",
    "\n",
    "        # Save the generated image samples to a file\n",
    "        sample_dir = r\"E:\\Tensorflow\\All_Projects\\Autoencoder\\MNIST_images_generated\"\n",
    "        if not os.path.exists(sample_dir):\n",
    "            os.makedirs(sample_dir)\n",
    "        filename = f\"{sample_dir}/mnist_{epoch}.png\"\n",
    "        plt.savefig(filename)\n",
    "        # plt.show()\n",
    "\n",
    "        # Create a GIF of the generated image samples\n",
    "        with imageio.get_writer(f\"{sample_dir}/mnist.gif\", mode='I') as writer:\n",
    "            for i in range(epoch):\n",
    "                filename = f\"{sample_dir}/mnist_{i}.png\"\n",
    "                writer.append_data(imageio.imread(filename))\n",
    "        writer.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jrrvRu8DF7uU",
    "outputId": "79da48df-d5c1-4852-c727-efd1de8aef1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 137,217\n",
      "Trainable params: 137,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_7 (Dense)             (None, 512)               5632      \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 512)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 784)               402192    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 670,480\n",
      "Trainable params: 670,480\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 3s 0us/step\n",
      "2/2 [==============================] - 2s 3ms/step\n",
      "0 [D loss: 0.71, acc: 42.19%] [G loss: 0.95, mse: 0.95]\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "1 [D loss: 0.69, acc: 48.44%] [G loss: 0.92, mse: 0.92]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2 [D loss: 0.67, acc: 63.28%] [G loss: 0.90, mse: 0.90]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "3 [D loss: 0.60, acc: 89.84%] [G loss: 0.86, mse: 0.86]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "4 [D loss: 0.46, acc: 85.94%] [G loss: 0.77, mse: 0.77]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "5 [D loss: 0.33, acc: 89.84%] [G loss: 0.64, mse: 0.64]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "6 [D loss: 0.30, acc: 88.28%] [G loss: 0.53, mse: 0.52]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "7 [D loss: 0.29, acc: 88.28%] [G loss: 0.41, mse: 0.40]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "8 [D loss: 0.28, acc: 90.62%] [G loss: 0.33, mse: 0.32]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "9 [D loss: 0.27, acc: 91.41%] [G loss: 0.32, mse: 0.31]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "10 [D loss: 0.24, acc: 94.53%] [G loss: 0.28, mse: 0.27]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "11 [D loss: 0.24, acc: 92.97%] [G loss: 0.29, mse: 0.28]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "12 [D loss: 0.21, acc: 96.09%] [G loss: 0.26, mse: 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "13 [D loss: 0.19, acc: 100.00%] [G loss: 0.27, mse: 0.27]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "14 [D loss: 0.20, acc: 97.66%] [G loss: 0.28, mse: 0.27]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "15 [D loss: 0.17, acc: 100.00%] [G loss: 0.27, mse: 0.26]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "16 [D loss: 0.17, acc: 99.22%] [G loss: 0.27, mse: 0.27]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "17 [D loss: 0.17, acc: 99.22%] [G loss: 0.26, mse: 0.26]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "18 [D loss: 0.16, acc: 100.00%] [G loss: 0.27, mse: 0.26]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "19 [D loss: 0.16, acc: 100.00%] [G loss: 0.28, mse: 0.28]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "20 [D loss: 0.14, acc: 100.00%] [G loss: 0.26, mse: 0.26]\n",
      "1/1 [==============================] - 0s 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ZUBAIR\\AppData\\Local\\Temp\\ipykernel_13896\\750853383.py:152: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  fig, axs = plt.subplots(r, c, figsize=(10, 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "21 [D loss: 0.13, acc: 100.00%] [G loss: 0.26, mse: 0.26]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 996us/step\n",
      "22 [D loss: 0.12, acc: 100.00%] [G loss: 0.26, mse: 0.26]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "23 [D loss: 0.12, acc: 99.22%] [G loss: 0.25, mse: 0.24]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "24 [D loss: 0.11, acc: 100.00%] [G loss: 0.26, mse: 0.26]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "25 [D loss: 0.12, acc: 100.00%] [G loss: 0.26, mse: 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 997us/step\n",
      "26 [D loss: 0.11, acc: 100.00%] [G loss: 0.25, mse: 0.24]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "27 [D loss: 0.10, acc: 100.00%] [G loss: 0.26, mse: 0.25]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "28 [D loss: 0.10, acc: 100.00%] [G loss: 0.27, mse: 0.26]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "29 [D loss: 0.11, acc: 99.22%] [G loss: 0.26, mse: 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "30 [D loss: 0.09, acc: 100.00%] [G loss: 0.24, mse: 0.24]\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "31 [D loss: 0.08, acc: 100.00%] [G loss: 0.26, mse: 0.25]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "32 [D loss: 0.08, acc: 100.00%] [G loss: 0.23, mse: 0.22]\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "33 [D loss: 0.08, acc: 100.00%] [G loss: 0.26, mse: 0.25]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "34 [D loss: 0.09, acc: 100.00%] [G loss: 0.24, mse: 0.24]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "35 [D loss: 0.08, acc: 100.00%] [G loss: 0.22, mse: 0.22]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "36 [D loss: 0.09, acc: 100.00%] [G loss: 0.24, mse: 0.23]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "37 [D loss: 0.07, acc: 100.00%] [G loss: 0.22, mse: 0.22]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "38 [D loss: 0.07, acc: 100.00%] [G loss: 0.23, mse: 0.22]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "39 [D loss: 0.07, acc: 100.00%] [G loss: 0.23, mse: 0.22]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 993us/step\n",
      "40 [D loss: 0.07, acc: 100.00%] [G loss: 0.22, mse: 0.22]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "41 [D loss: 0.06, acc: 100.00%] [G loss: 0.23, mse: 0.22]\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "42 [D loss: 0.06, acc: 100.00%] [G loss: 0.22, mse: 0.21]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "43 [D loss: 0.06, acc: 100.00%] [G loss: 0.22, mse: 0.21]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "44 [D loss: 0.06, acc: 100.00%] [G loss: 0.22, mse: 0.21]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "45 [D loss: 0.05, acc: 100.00%] [G loss: 0.21, mse: 0.20]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "46 [D loss: 0.05, acc: 100.00%] [G loss: 0.23, mse: 0.22]\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "47 [D loss: 0.06, acc: 99.22%] [G loss: 0.21, mse: 0.21]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "48 [D loss: 0.05, acc: 100.00%] [G loss: 0.22, mse: 0.21]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "49 [D loss: 0.05, acc: 99.22%] [G loss: 0.20, mse: 0.19]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "50 [D loss: 0.06, acc: 98.44%] [G loss: 0.21, mse: 0.21]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "51 [D loss: 0.06, acc: 100.00%] [G loss: 0.20, mse: 0.19]\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "52 [D loss: 0.06, acc: 98.44%] [G loss: 0.21, mse: 0.20]\n",
      "1/1 [==============================] - 0s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    autoencoder = AdversarialAutoencoder()\n",
    "    autoencoder.train(epochs=600, batch_size=64, sample_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o3Uk690tF7w3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XoJo8Gp8F7zu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0HzbHUQpF72Z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LJElZFa8F75R"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LpasnlzAF8Fu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u5xckkm5F8Ks"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RClep_7zF8Nb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bwzTUeFfF8Xa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "15jj8hnnF8Z5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pch_oB_7F8dk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Nv4F-w8PF8gF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAzZiKbtF8is"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onWlt6IlF8lM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dO4t3EwIF8n0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65cRSTYGF8q7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVka11UbF8t2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIBkGQdXF8wt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia_OBOMUF8zc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DQ_C4ioF82N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zj1FDjW-F85C"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ka1litEF88H"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R08HW_iOF8-y"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TgWoXLLF9B0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XVImMMT2F9E6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qyjwToLUF9Hq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
